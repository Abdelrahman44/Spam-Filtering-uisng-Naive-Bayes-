{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8fc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06608f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download english stopwords and punctuation marks:\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4e047-30de-4832-aa6c-d3c96f6a2bfc",
   "metadata": {},
   "source": [
    "# 1. Defining helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6231b1-a581-4a2c-a21c-6c129a294a63",
   "metadata": {},
   "source": [
    "### 1.1 pre-processing functions and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42086c5-207d-44ed-96b5-c74cd8820ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-processing functions for single text\n",
    "def lower(sentence):\n",
    "    s = str(sentence)\n",
    "    return s.lower()\n",
    "\n",
    "def remove_subject(sentence):\n",
    "    sentence = sentence[1:]\n",
    "    return sentence\n",
    "\n",
    "def tokenize(sentence): \n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def remove_stop_words(sentence):\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    return tuple(item for item in sentence if item not in stop_words and item.isalnum())\n",
    "\n",
    "\n",
    "def stem(sentence):\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    words = [stemmer.stem(word) for word in sentence]\n",
    "    return words\n",
    "\n",
    "def preprocess_sentence(sentence, func1=lower, func2=remove_subject, func3=tokenize, func4=remove_stop_words, func5=stem): #full pre-prcessing pipeline\n",
    "    return func5(func4(func3(func2(func1(sentence)))))\n",
    "\n",
    "\n",
    "## pre-processing functions for list of texts\n",
    "def lower_list(sentence_list):\n",
    "    sentence_list=sentence_list.str.lower()\n",
    "    return sentence_list\n",
    "\n",
    "def tokenize_list(sentence_list): \n",
    "    sentence_list = list(map(nltk.word_tokenize, sentence_list))\n",
    "    return sentence_list\n",
    "\n",
    "def remove_subject_list(sentence_list):\n",
    "    sentence_list = list(map(lambda x: x[1:], sentence_list))\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def remove_stop_words_list(sentence_list):\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    sentence_list = list(map(lambda x: tuple(item for item in x if item not in stop_words and item.isalpha()), sentence_list))\n",
    "    return sentence_list\n",
    "\n",
    "def stem_list(sentence_list):   # stemming & lemmatizing\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    #stemmer = nltk.stem.PorterStemmer()\n",
    "    #stemmer = nltk.stem.LancasterStemmer()\n",
    "    \n",
    "    all_words = []\n",
    "    for sentence in sentence_list:\n",
    "        words_list = []\n",
    "        for word in sentence:\n",
    "            words_list.append(stemmer.stem(word))\n",
    "            \n",
    "        all_words.append(tuple(words_list))\n",
    "        \n",
    "    return all_words\n",
    "\n",
    "\n",
    "def preprocess_sentence_list(sentence, func1=lower_list, func2=tokenize_list, \n",
    "                             func3=remove_subject_list, func4=remove_stop_words_list, func5=stem_list): #full pre-processing pipeline\n",
    "    return func4(func3(func2(func1(sentence))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d4948-c4d9-4a06-a422-5484dca4efed",
   "metadata": {},
   "source": [
    "### 1.2 Naive Bayes functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e84e96-f565-4f4d-b633-5ad467065e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB with Laplacian smoothing\n",
    "\n",
    "def classes_probability(data):\n",
    "    P_spam = (data.value_counts()[1]+1)/(sum(data.value_counts()) + len(data.value_counts()))\n",
    "    P_ham = (data.value_counts()[0]+1)/(sum(data.value_counts()) + len(data.value_counts()))\n",
    "    return (P_spam, P_ham)\n",
    "\n",
    "def words_probability_per_class(train):\n",
    "    # make a dictionary of unique words and the probability of each word\n",
    "    freqs = nltk.FreqDist(word for sentence in train['text'] for word in sentence) #frequency of each word\n",
    "    num_unique_words = freqs.N()\n",
    "    num_total_words = sum(len(x) for x in train['text'])\n",
    "    words_dict= dict(freqs.items())\n",
    "    #words_dict = {k: v/total_words for k, v in words_dict.items()} # probability of each word p(word)\n",
    "    \n",
    "    train_spam = train[train['spam']==1] # filter spam samples\n",
    "    train_spam.reset_index(inplace=True) \n",
    "    train_spam.drop(columns=['index'], inplace=True)\n",
    "\n",
    "    train_ham = train[train['spam']==0] # filter ham samples\n",
    "    train_ham.reset_index(inplace=True) \n",
    "    train_ham.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## dictionary of P(w|C) for word in each class\n",
    "    # frequency of each word in each class\n",
    "    spam_freq = nltk.FreqDist(word for i in range(len(train_spam[\"text\"])) for word in train_spam[\"text\"][i]) \n",
    "    ham_freq = nltk.FreqDist(word for i in range(len(train_ham[\"text\"])) for word in train_ham[\"text\"][i]) \n",
    "\n",
    "    spam_words_dict=dict(spam_freq.items())\n",
    "    ham_words_dict=dict(ham_freq.items())\n",
    "    \n",
    "    num_total_spam_words = sum(len(x) for x in train_spam['text'])\n",
    "    num_total_ham_words = sum(len(x) for x in train_ham['text'])\n",
    "    \n",
    "\n",
    "    # laplacian-smoothed P(W|C)\n",
    "    spam_words_dict = {k: (v+1)/(num_total_spam_words+num_unique_words) for k, v in spam_words_dict.items()}\n",
    "    spam_words_dict['num_total_spam_words'] = num_total_spam_words\n",
    "    ham_words_dict = {k: (v+1)/(num_total_ham_words+num_unique_words) for k, v in ham_words_dict.items()}\n",
    "    ham_words_dict['num_total_ham_words'] = num_total_ham_words\n",
    "\n",
    "    \n",
    "    \n",
    "    return (spam_words_dict, ham_words_dict, num_unique_words)\n",
    "\n",
    "\n",
    "def determine_spam(words, num_unique_words, spam_words_dict, ham_words_dict, P_spam, P_ham):\n",
    "    if(type(words)==list or type(words)==pd.core.series.Series):\n",
    "        return determine_spam_dict(words, num_unique_words, spam_words_dict, ham_words_dict, P_spam, P_ham) \n",
    "    else:\n",
    "        return determine_spam_single(words, num_unique_words, spam_words_dict, ham_words_dict, P_spam, P_ham)\n",
    "    \n",
    "def determine_spam_dict(sentence_dict, num_unique_words, spam_words_dict, ham_words_dict, P_spam, P_ham):\n",
    "    results = []\n",
    "    for sentence in sentence_dict:\n",
    "        # get P(w|spam) for each word, for words in the training set\n",
    "        lis_spam_probs = [spam_words_dict[word] if word in spam_words_dict \n",
    "                          else 1/(spam_words_dict['num_total_spam_words']+num_unique_words) for word in sentence] \n",
    "        # get P(w|spam) for each word, for words not in the taining set\n",
    "        lis_ham_probs = [ham_words_dict[word] if word in ham_words_dict \n",
    "                         else 1/(ham_words_dict['num_total_ham_words']+num_unique_words) for word in sentence] \n",
    "        \n",
    "        p1 = P_spam * np.prod(lis_spam_probs)\n",
    "        p2 = P_ham * np.prod(lis_ham_probs)\n",
    "        \n",
    "        if (p1 > p2):\n",
    "            results.append(1)\n",
    "                \n",
    "        else:\n",
    "            results.append(0)\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def determine_spam_single(words, words_dict, spam_words_dict, ham_words_dict, P_spam, P_ham):\n",
    "    lis_spam_probs = [spam_words_dict[word] if word in spam_words_dict \n",
    "                          else 1/(spam_words_dict['num_total_spam_words']+num_unique_words) for word in words] \n",
    "    lis_ham_probs = [ham_words_dict[word] if word in ham_words_dict \n",
    "                         else 1/(ham_words_dict['num_total_ham_words']+num_unique_words) for word in sentence]\n",
    "    p1 = P_spam * np.prod(lis_spam_probs)\n",
    "    p2 = P_ham * np.prod(lis_ham_probs)\n",
    "\n",
    "    if (p1 > p2):\n",
    "        print('spam')\n",
    "    else:\n",
    "        print('ham')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd3dc7-41a3-4b28-8c9e-9318e591725a",
   "metadata": {},
   "source": [
    "# 2. Workin on development data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5c2ef-0ec8-4871-a6f1-5ca389c15cc0",
   "metadata": {},
   "source": [
    "## 2.1 Data split and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695bc88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"/workspace/new_src/dataset/emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8441999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d819ea-1d61-4d1a-a0ab-3ad617bb9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and test sets\n",
    "train, test = train_test_split(all_data, test_size=0.3, random_state=42, shuffle=True)\n",
    "train.to_csv(\"/workspace/new_src/dataset/train.csv\", index=False)\n",
    "test.to_csv(\"/workspace/new_src/dataset/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d221e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ef9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tokens = preprocess_sentence_list(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9fe752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>(volatility, curves, linked, reuters, hi, tany...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>(organizational, announcement, fyi, forwarded,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>(lng, meeting, hello, lng, meeting, held, morn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>(fwd, optical, network, engineering, enron, re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>(argentina, modelling, michael, p, thursday, v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "3931  (volatility, curves, linked, reuters, hi, tany...     0\n",
       "4056  (organizational, announcement, fyi, forwarded,...     0\n",
       "4546  (lng, meeting, hello, lng, meeting, held, morn...     0\n",
       "2471  (fwd, optical, network, engineering, enron, re...     0\n",
       "2481  (argentina, modelling, michael, p, thursday, v...     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"] = preprocessed_tokens\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9689076",
   "metadata": {},
   "source": [
    "## 2.2 Calculate needed probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d57d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23136374968835702 0.768636250311643\n"
     ]
    }
   ],
   "source": [
    "# P(C)\n",
    "(P_spam, P_ham) = classes_probability(train['spam'])\n",
    "print(P_spam, P_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2047d37-8e7e-40a8-b14f-fa0e2a280698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(W|C)\n",
    "spam_words_dict, ham_words_dict, num_unique_words = words_probability_per_class(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db94773",
   "metadata": {},
   "source": [
    "## 2.3 Evaluate on development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63fa36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_precitions = determine_spam(train_df['text'], num_unique_words, spam_words_dict, ham_words_dict, \n",
    "                                 P_spam, P_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bd6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_df['spam'] == list_precitions # get list where TP+TN is True and FP+FN is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bbf0494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8822649039660764 0.8822649039660764\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = results.value_counts()[1]/(results.value_counts()[0]+results.value_counts()[1])\n",
    "accuracy2 = metrics.accuracy_score(train_df['spam'], list_precitions)\n",
    "print(accuracy1, accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92c4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "results2 = train['spam'] & list_precitions\n",
    "results2.value_counts()\n",
    "precision1 = results2.value_counts()[1]/(np.sum(list_precitions))\n",
    "precision2 = metrics.precision_score(train_df['spam'], list_precitions)\n",
    "print(precision1, precision2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c983d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49083063646170444\n"
     ]
    }
   ],
   "source": [
    "recall2 = metrics.recall_score(train['spam'], list_precitions)\n",
    "print(recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0727639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658465991316932 0.658465991316932\n"
     ]
    }
   ],
   "source": [
    "f1 = 2*(precision1*recall2)/(precision1+recall2)\n",
    "f2 = metrics.f1_score(train['spam'],list_precitions)\n",
    "print(f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "104e08aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7aa301da00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_max = metrics.confusion_matrix(train['spam'], list_precitions,labels=[0,1])\n",
    "metrics.ConfusionMatrixDisplay(conf_max, display_labels=[0, 1]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715abacf",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ef25a",
   "metadata": {},
   "source": [
    "### Batch emails filtering (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cfbdbf7-3ea6-4e3f-9c62-46e96dd25b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: re : energy derivatives conference - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: financial maths course , part 2  vinc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: re : bullet points  please respond to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: re : enron default swaps  darrell ,  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : power question  steve ,  elena c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: re : energy derivatives conference - ...     0\n",
       "1  Subject: financial maths course , part 2  vinc...     0\n",
       "2  Subject: re : bullet points  please respond to...     0\n",
       "3  Subject: re : enron default swaps  darrell ,  ...     0\n",
       "4  Subject: re : power question  steve ,  elena c...     0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/workspace/new_src/dataset/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54e41105",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tokens = preprocess_sentence_list(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6416041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"text\"] = preprocessed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6335dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_precitions = determine_spam(test['text'], num_unique_words, spam_words_dict, ham_words_dict, \n",
    "                                 P_spam, P_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e100db",
   "metadata": {},
   "source": [
    "# 4. Perfromance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57bb26",
   "metadata": {},
   "source": [
    "### 4.1 Accuracy metric: (TP+TN)/(TP+FP+TN+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0c8192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1453\n",
       "False     266\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = test['spam'] == list_precitions # get list where TP+TN is True and FP+FN is False\n",
    "results.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75b92b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452588714368819"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = results.value_counts()[1]/(results.value_counts()[0]+results.value_counts()[1])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23ff9ab1-7557-4c2f-91aa-6e44e7055217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452588714368819"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(test['spam'], list_precitions)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f15ba",
   "metadata": {},
   "source": [
    "### 4.2 Precision metric: TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abaeba2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1544\n",
       "True      175\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = test['spam'] & list_precitions\n",
    "results2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24e594c7-fed9-4d1a-9351-345effbd8bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = results2.value_counts()[1]/(np.sum(list_precitions))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b15c7887-1cd1-4dde-9765-7de23454aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = metrics.precision_score(test['spam'], list_precitions)\n",
    "prec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc185a94",
   "metadata": {},
   "source": [
    "### 4.3 Recall metric: TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c8455e6-74c7-4350-a6c3-72eb556caa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN = [1 for i in range(len(test['spam'])) if test['spam'][i] == 1 and list_precitions[i] == 0]\n",
    "np.sum(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b101ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3968253968253968"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = results2.value_counts()[1]/(results2.value_counts()[1]+np.sum(FN))\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18a962ff-6923-42c9-9dae-2b463a3e278a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3968253968253968"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = metrics.recall_score(test['spam'], list_precitions)\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d50c8",
   "metadata": {},
   "source": [
    "### 4.4 F1 metric: 2*(Precission*Recall)/(Precession+Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ee28376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5681818181818182"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e546d75a-c76c-41e7-bfab-ac964c2734a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5681818181818182"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_sk = metrics.f1_score(test['spam'],list_precitions)\n",
    "f1_sk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
